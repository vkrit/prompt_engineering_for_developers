{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4eS0p9tFjJZ4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oIiKAPtLmMwx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_file_name = \"training_data.jsonl\"\n",
    "\n",
    "res = client.files.create(\n",
    "  file=open(training_file_name, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "file_id = res.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model='gpt-4'):\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dfIy9C7j5vj",
    "outputId": "7e1a1b5c-7182-4edc-cbdf-9fb83862213d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-WrjzKEVW8x6FHIWOyRRV82u4\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "ft_res = client.fine_tuning.jobs.create(\n",
    "  training_file=file_id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "print(\"Job ID:\", ft_res.id)\n",
    "print(\"Status:\", ft_res.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ikm8lcbdkCaf",
    "outputId": "a21c0f10-e96a-4bc5-d9fc-84431c83227c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-WrjzKEVW8x6FHIWOyRRV82u4', created_at=1699974085, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-5DvmRlg7kGvkcggchTvEJDF0', result_files=[], status='validating_files', trained_tokens=None, training_file='file-cG6DhxnKEz2O4f66jWP8srDd', validation_file=None), FineTuningJob(id='ftjob-OIjGfoUk0nd8HC2Vt7nz9kt5', created_at=1699972109, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-5DvmRlg7kGvkcggchTvEJDF0', result_files=[], status='cancelled', trained_tokens=None, training_file='file-7hHkfu1u7LzfO4HCOzQ5M2Nn', validation_file=None), FineTuningJob(id='ftjob-r5B9uaRDRCxpHmXj8y3jNkt7', created_at=1699971420, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-5DvmRlg7kGvkcggchTvEJDF0', result_files=[], status='cancelled', trained_tokens=None, training_file='file-lS4AuVmtyOHg5SCEfiuRhlGp', validation_file=None), FineTuningJob(id='ftjob-zLDX7NIVG7iG3l0RfKFY9FGy', created_at=1699970777, error=Error(code='invalid_n_examples', message='Training file has 7 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-5DvmRlg7kGvkcggchTvEJDF0', result_files=[], status='failed', trained_tokens=None, training_file='file-cBBDKYp8SANC6TlFebzlNg4n', validation_file=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-WrjzKEVW8x6FHIWOyRRV82u4\n",
      "Status: succeeded\n",
      "Trained Tokens: 4210\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "response = client.fine_tuning.jobs.retrieve(\"ftjob-WrjzKEVW8x6FHIWOyRRV82u4\")\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cancel a job\n",
    "client.fine_tuning.jobs.cancel(\"ftjob-OIjGfoUk0nd8HC2Vt7nz9kt5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-WrjzKEVW8x6FHIWOyRRV82u4\n",
      "Validating training file: file-cG6DhxnKEz2O4f66jWP8srDd\n",
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n",
      "Step 1/100: training loss=0.83\n",
      "Step 11/100: training loss=2.84\n",
      "Step 21/100: training loss=0.01\n",
      "Step 31/100: training loss=1.19\n",
      "Step 41/100: training loss=0.02\n",
      "Step 51/100: training loss=0.00\n",
      "Step 61/100: training loss=0.67\n",
      "Step 71/100: training loss=0.00\n",
      "Step 81/100: training loss=0.22\n",
      "Step 91/100: training loss=0.00\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal::8KqXmPZh\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# List up to 50 events from a fine-tuning job\n",
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-WrjzKEVW8x6FHIWOyRRV82u4\", limit=50)\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0613:personal::8KqXmPZh\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "response = client.fine_tuning.jobs.retrieve(\"ftjob-WrjzKEVW8x6FHIWOyRRV82u4\")\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None: \n",
    "    raise RuntimeError(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "# client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUvGmPSkbAL"
   },
   "source": [
    "### Use your fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ruVeuJCuLEZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NZVF6Qh2kwWD",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, it is not legal to drive a car shirtless in Thailand.\n",
      "The Prime Minister of Thailand is Prayuth Chan-o-cha.\n",
      "There are approximately 35,000 temples in Thailand.\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = \"ft:gpt-3.5-turbo-0613:personal::8KqXmPZh\"\n",
    "\n",
    "new_prompt = \"Is it legal to drive a car shirtless in Thailand?\"\n",
    "response = get_completion(new_prompt, fine_tuned_model)\n",
    "print(response)\n",
    "\n",
    "new_prompt = \"Who is the priminister of Thailand?\"\n",
    "response = get_completion(new_prompt, fine_tuned_model)\n",
    "print(response)\n",
    "\n",
    "new_prompt = \"How many temples are in Thailand?\"\n",
    "response = get_completion(new_prompt, fine_tuned_model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
