{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll_sa81DjnZ4",
        "outputId": "c7afc937-c223-4324-8a62-081d795229b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4eS0p9tFjJZ4"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset\n",
        "{\n",
        "\"prompt\": \"my prompt ->\",\n",
        "\"completion\": \"the answer of the prompt. \\n\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "aGSV09j6jWW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = [\n",
        "\t{\n",
        "    \t\"prompt\": \"What is the capital of France?->\",\n",
        "    \t\"completion\": \"\"\" The capital of France is Paris.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"What is the primary function of the heart?->\",\n",
        "    \t\"completion\": \"\"\" The primary function of the heart is to pump blood throughout the body.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"What is photosynthesis?->\",\n",
        "    \t\"completion\": \"\"\" Photosynthesis is the process by which green plants and some other organisms convert sunlight into chemical energy stored in the form of glucose.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"Who wrote the play 'Romeo and Juliet'?->\",\n",
        "    \t\"completion\": \"\"\" William Shakespeare wrote the play 'Romeo and Juliet'.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"Which element has the atomic number 1?->\",\n",
        "    \t\"completion\": \"\"\" Hydrogen has the atomic number 1.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"What is the largest planet in our solar system?->\",\n",
        "    \t\"completion\": \"\"\" Jupiter is the largest planet in our solar system.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"What is the freezing point of water in Celsius?->\",\n",
        "    \t\"completion\": \"\"\" The freezing point of water in Celsius is 0 degrees.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"What is the square root of 144?->\",\n",
        "    \t\"completion\": \"\"\" The square root of 144 is 12.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"Who is the author of 'To Kill a Mockingbird'?->\",\n",
        "    \t\"completion\": \"\"\" The author of 'To Kill a Mockingbird' is Harper Lee.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"What is the smallest unit of life?->\",\n",
        "    \t\"completion\": \"\"\" The smallest unit of life is the cell.\\n\"\"\"\n",
        "\t},\n",
        "\t{\n",
        "    \t\"prompt\": \"Who is the priminister of Thailand?->\",\n",
        "    \t\"completion\": \"\"\" Mr. Pita Limchareonrat\\n\"\"\"\n",
        "\t}\n",
        "]\n"
      ],
      "metadata": {
        "id": "XBWIYiebjSOq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare files to upload"
      ],
      "metadata": {
        "id": "MV4CA24djy2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "training_file_name = \"training_data.jsonl\"\n",
        "\n",
        "def prepare_data(dictionary_data, final_file_name):\n",
        "  with open(final_file_name, 'w') as outfile:\n",
        "    for entry in dictionary_data:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')\n",
        "\n",
        "prepare_data(training_data, \"training_data.jsonl\")"
      ],
      "metadata": {
        "id": "2C2OvudkjzK-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_data_to_OpenAI(filename):\n",
        "  with open(filename, \"rb\") as dataset_file:\n",
        "    response = openai.Dataset.create(\n",
        "        file=dataset_file,\n",
        "        purpose=\"fine-tuning\",\n",
        "        name=\"questions_answers_dataset\"\n",
        "    )\n",
        "  return response[\"id\"]\n"
      ],
      "metadata": {
        "id": "oIiKAPtLmMwx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f \"training_data.jsonl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dfIy9C7j5vj",
        "outputId": "7e1a1b5c-7182-4edc-cbdf-9fb83862213d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 11 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- All prompts end with suffix `?->`\n",
            "- All prompts start with prefix `Wh`\n",
            "- All completions end with suffix `\\n`\n",
            "\n",
            "No remediations found.\n",
            "\n",
            "You can use your file for fine-tuning:\n",
            "> openai api fine_tunes.create -t \"training_data.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.59 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"training_data.jsonl\" -m \"curie\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikm8lcbdkCaf",
        "outputId": "a21c0f10-e96a-4bc5-d9fc-84431c83227c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/1.41k [00:00<?, ?it/s]\rUpload progress: 100% 1.41k/1.41k [00:00<00:00, 1.30Mit/s]\n",
            "Uploaded file from training_data.jsonl: file-sTzqEgYgUrYKg4Wawz4PswkA\n",
            "Created fine-tune: ft-NiHENGzjzSIS37Pc8HAYp7Fa\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-06-29 06:03:47] Created fine-tune: ft-NiHENGzjzSIS37Pc8HAYp7Fa\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-NiHENGzjzSIS37Pc8HAYp7Fa\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-NiHENGzjzSIS37Pc8HAYp7Fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaHr5TbBpakO",
        "outputId": "44e3e035-9f59-4546-d1cd-c68bdc4d67d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-06-29 05:33:16] Created fine-tune: ft-nBpBzRcC3QZvXLftT2gUSISs\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-nBpBzRcC3QZvXLftT2gUSISs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all created fine-tunes\n",
        "!openai api fine_tunes.list\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqv7myMbpsiK",
        "outputId": "8adb9fce-d00d-4c58-dc2b-bcd16e3904d1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"fine-tune\",\n",
            "      \"id\": \"ft-nBpBzRcC3QZvXLftT2gUSISs\",\n",
            "      \"hyperparams\": {\n",
            "        \"n_epochs\": 4,\n",
            "        \"batch_size\": null,\n",
            "        \"prompt_loss_weight\": 0.01,\n",
            "        \"learning_rate_multiplier\": null\n",
            "      },\n",
            "      \"organization_id\": \"org-5DvmRlg7kGvkcggchTvEJDF0\",\n",
            "      \"model\": \"davinci\",\n",
            "      \"training_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-kRRpt3KvorsOei3GZyFPDWQy\",\n",
            "          \"purpose\": \"fine-tune\",\n",
            "          \"filename\": \"training_data.jsonl\",\n",
            "          \"bytes\": 1310,\n",
            "          \"created_at\": 1688016796,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"validation_files\": [],\n",
            "      \"result_files\": [],\n",
            "      \"created_at\": 1688016796,\n",
            "      \"updated_at\": 1688018323,\n",
            "      \"status\": \"cancelled\",\n",
            "      \"fine_tuned_model\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine-tune\",\n",
            "      \"id\": \"ft-NiHENGzjzSIS37Pc8HAYp7Fa\",\n",
            "      \"hyperparams\": {\n",
            "        \"n_epochs\": 4,\n",
            "        \"batch_size\": null,\n",
            "        \"prompt_loss_weight\": 0.01,\n",
            "        \"learning_rate_multiplier\": null\n",
            "      },\n",
            "      \"organization_id\": \"org-5DvmRlg7kGvkcggchTvEJDF0\",\n",
            "      \"model\": \"curie\",\n",
            "      \"training_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-sTzqEgYgUrYKg4Wawz4PswkA\",\n",
            "          \"purpose\": \"fine-tune\",\n",
            "          \"filename\": \"training_data.jsonl\",\n",
            "          \"bytes\": 1405,\n",
            "          \"created_at\": 1688018627,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"validation_files\": [],\n",
            "      \"result_files\": [],\n",
            "      \"created_at\": 1688018627,\n",
            "      \"updated_at\": 1688018627,\n",
            "      \"status\": \"pending\",\n",
            "      \"fine_tuned_model\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune. The resulting object includes\n",
        "# job status (which can be one of pending, running, succeeded, or failed)\n",
        "# and other information\n",
        "!openai api fine_tunes.get -i ft-NiHENGzjzSIS37Pc8HAYp7Fa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqbB7q3ZrGha",
        "outputId": "ec0ec97b-5542-4a5e-8c64-eb9262cc50f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"id\": \"ft-NiHENGzjzSIS37Pc8HAYp7Fa\",\n",
            "  \"hyperparams\": {\n",
            "    \"n_epochs\": 4,\n",
            "    \"batch_size\": null,\n",
            "    \"prompt_loss_weight\": 0.01,\n",
            "    \"learning_rate_multiplier\": null\n",
            "  },\n",
            "  \"organization_id\": \"org-5DvmRlg7kGvkcggchTvEJDF0\",\n",
            "  \"model\": \"curie\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-sTzqEgYgUrYKg4Wawz4PswkA\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"training_data.jsonl\",\n",
            "      \"bytes\": 1405,\n",
            "      \"created_at\": 1688018627,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"validation_files\": [],\n",
            "  \"result_files\": [],\n",
            "  \"created_at\": 1688018627,\n",
            "  \"updated_at\": 1688018627,\n",
            "  \"status\": \"pending\",\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"object\": \"fine-tune-event\",\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-NiHENGzjzSIS37Pc8HAYp7Fa\",\n",
            "      \"created_at\": 1688018627\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cancel a job\n",
        "!openai api fine_tunes.cancel -i ft-nBpBzRcC3QZvXLftT2gUSISs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwfhnuDBrHqi",
        "outputId": "04f6bfda-25b8-4345-d3a7-aed6aa2aeba0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"id\": \"ft-nBpBzRcC3QZvXLftT2gUSISs\",\n",
            "  \"hyperparams\": {\n",
            "    \"n_epochs\": 4,\n",
            "    \"batch_size\": null,\n",
            "    \"prompt_loss_weight\": 0.01,\n",
            "    \"learning_rate_multiplier\": null\n",
            "  },\n",
            "  \"organization_id\": \"org-5DvmRlg7kGvkcggchTvEJDF0\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-kRRpt3KvorsOei3GZyFPDWQy\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"training_data.jsonl\",\n",
            "      \"bytes\": 1310,\n",
            "      \"created_at\": 1688016796,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"validation_files\": [],\n",
            "  \"result_files\": [],\n",
            "  \"created_at\": 1688016796,\n",
            "  \"updated_at\": 1688018323,\n",
            "  \"status\": \"cancelled\",\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"object\": \"fine-tune-event\",\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-nBpBzRcC3QZvXLftT2gUSISs\",\n",
            "      \"created_at\": 1688016796\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine-tune-event\",\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune cancelled\",\n",
            "      \"created_at\": 1688018323\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use your fine-tune model"
      ],
      "metadata": {
        "id": "WHUvGmPSkbAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "1ruVeuJCuLEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model = \"\"\n",
        "\n",
        "new_prompt = \"What is photosynthesis?\"\n",
        "response = get_completion(new_prompt)\n",
        "print(response)\n",
        "\n",
        "new_prompt = \"Who is the prime minister of Thailand?\"\n",
        "response = get_completion(new_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "NZVF6Qh2kwWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}